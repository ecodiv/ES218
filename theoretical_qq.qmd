# The theoretical q-q


```{r echo=FALSE}
source("libs/Common.R")
```


```{r echo = FALSE}
pkg_ver(c("dplyr", "ggplot2","lattice", "tidyr"))
```


## Introduction

Thus far, we have used the quantile-quantile plots to compare the distributions between two empirical (i.e. observational) datasets. This is sometimes referred to as an *empirical Q-Q plot*. We can also use the q-q plot to compare an empirical distribution to a theoretical distribution (i.e. one defined mathematically). Such a plot is usually referred to as a *theoretical Q-Q plot*. Examples of popular theoretical distribution are the normal distribution (aka the Gaussian distribution), the chi-square distribution, and the exponential distribution just to name a few.

```{r, fig.height=2, fig.width=7, echo=FALSE}
OP <- par( mfrow=c(1,4))
x <- seq(-5, 5, 0.1)
plot(dnorm(x,0,1) ~ x, type = "l",axes = FALSE, ylab = NA, xlab = "Normal")
x <- seq(0, 20, 0.1)
plot(dchisq(x,3,1) ~ x, type = "l",axes = FALSE, ylab = NA, xlab = "Chi-square")
x <- seq(0, 10, 0.1)
plot(dexp(x,1) ~ x, type = "l",axes = FALSE, ylab = NA, xlab = ("Exponential"))
par(OP)
```

There are many reasons we might want to compare empirical data to theoretical distributions:

 * A theoretical distribution is easy to parameterize. For example, if the shape of the distribution of a batch of numbers can be approximated by a normal distribution we can reduce the complexity of our data to just two values: the mean and the standard deviation.
 
 * If data can be approximated by certain theoretical distributions, then many mainstream statistical procedures can be applied to the data.
 
 * In inferential statistics, knowing that a sample was derived from a population whose distribution follows a theoretical distribution allows us to derive certain properties of the population from the sample. For example, if we know that a sample comes from a normally distributed population, we can define confidence intervals for the sample mean using a t-distribution.
 
 * Modeling the distribution of the observed data can provide insight into the underlying process that generated the data.
 
But very few empirical datasets follow any theoretical distributions exactly. So the questions usually ends up being "how well does theoretical distribution *X* fit my data?"

The theoretical quantile-quantile plot is a tool to explore how a batch of numbers deviates from a theoretical distribution and to visually assess whether the difference is significant for the purpose of the analysis. In the following examples, we will compare empirical data to the normal distribution using the **normal quantile-quantile** plot.

## The normal q-q plot

The *normal q-q plot* is just a special case of the *empirical q-q plot* we've explored so far; the difference being that we assign the normal distribution quantiles to the x-axis.

### Drawing a normal q-q plot from scratch

In the following example, we'll compare the `Alto 1` group to a normal distribution. We'll work off of the `Alto 1` height values.

The data manipulation steps include:
* Sorting the `height` values in ascending order;
* Computing the f-values (we'll adopt Cleveland's algorithm);
* Computing the matching quantile values from a *Normal* distribution (using the `qnorm` function).

 
```{r}
library(dplyr)

alto  <- lattice::singer %>% 
  filter(voice.part == "Alto 1") %>% 
  arrange(height) %>% 
  mutate(fval = (row_number() -0.5) / n(),
         x.norm = qnorm(fval))
```

Next, we'll plot the sorted `alto` values against the normal values using the base plotting environment.

```{r fig.height = 3, fig.width = 3, echo=2}
OP <-par(mar=c(4,4,1,1))
plot( height ~ x.norm, alto, type = "p", xlab = "Normal quantiles", pch = 20)
par(OP)
```

When comparing a batch of numbers to a theoretical distribution on a q-q plot, we are looking for significant deviation from a straight line. To make it easier to judge straightness, we can fit a line to the points. Note that we are **not** creating a 45&deg; (x=y) slope as was done with the empirical q-q plot--the range of values between both sets of numbers do not match. Here, we are only seeking the **straightness** of the point pattern.

There are many ways one can fit a line to the data, Cleveland opts to fit a line to the first and third quartile of the q-q plot. The following chunk of code identifies the quantiles for both the `alto` dataset and the theoretical normal distribution. It then computes the slope and intercept from these coordinates.

```{r}
# Find 1st and 3rd quartile for the Alto 1 data
y <- quantile(alto$height, c(0.25, 0.75), type = 5)

# Find the 1st and 3rd quartile of the normal distribution
x <- qnorm( c(0.25, 0.75))

# Now we can compute the intercept and slope of the line that passes
# through these points
slope <- diff(y) / diff(x)
int   <- y[1] - slope * x[1]
```

Next, we add the line to the plot.

```{r, fig.height = 3, fig.width = 3, echo=3}
OP <-par(mar=c(4,4,1,1))
plot( height ~ x.norm, alto, type = "p", xlab = "Normal quantiles", pch = 20)
abline(a = int, b = slope )
par(OP)
```


### Using R's built-in functions

R has two built-in functions that facilitate the plot building task when comparing a batch to a normal distribution: `qqnorm` and `qqline`. Note that the function `qqline` allows the user to define the quantile method via the `qtype=` parameter. Here, we set it to 5 to match the $f$-value calculation adopted in this course.

```{r fig.height=3, fig.width=3, echo=2:3, results='hold'}
OP <-par(mar=c(4,4,1,1))
qqnorm(alto$height)
qqline(alto$height, qtype = 5)
par(OP)
```

That's it. Just two lines of code!

### Using the ggplot2 plotting environment

#### `ggplot2` version 3.0 or greater

As of version 3.0, `ggplot` has  the `stat_qq_line` function (or `geom_qq_line`) that will generate the interquartile fit. So to generate the theoretical q-q plot, use the `stat_qq` function (or `geom_qq`) to generate the point plot, then call `stat_qq_line` to generate the IQR fit.

```{r, fig.height=3, fig.width=3}
library(ggplot2)

ggplot(alto, aes(sample = height)) + stat_qq(distribution = qnorm) + 
  stat_qq_line(line.p = c(0.25, 0.75), col = "blue") + 
  xlab("Unit normal quantile") + ylab("Height")

```

The `stat_qq_line` function uses the built-in `quantile` function and as such will adopt the default quantile type `7` (i.e. it computes the f-value as $(i - 1)/(n - 1))$. This differs from Cleveland's approach to computing the f-value. This setting cannot be changed in `stat_qq_line`.

## How normal is my dataset?

Simulations are a great way to develop an intuitive feel for what a dataset pulled from a normal distribution might look like in a normal Q-Q plot. You will seldom come across perfectly normal data in the real world. Noise is an inherent part of any underlying process. As such, random noise can influence the shape of a q-q plot despite the data coming from a normal distribution. This is especially true with small datasets as demonstrated in the following example where we simulate five small batches of values pulled from a normal distribution. The `rnorm` function is used in this example to randomly pick a number from a normal distribution whose mean is `0` and whose standard deviation is `1`. You can, of course, change the mean and standard deviation values to reflect the data being simulated.


```{r fig.height=3, fig.width=9}
set.seed(211)  # Sets random generator seed for consistent output
sim <- data.frame(sample = paste0("Sample",1:5),
                  value  = rnorm(20*5, mean = 0, sd = 1))

# Generate q-q plots of the simulated values
ggplot(sim, aes(sample = value)) + stat_qq(distribution = qnorm) +
  stat_qq_line(line.p = c(0.25, 0.75), col = "blue") +
  xlab("Unit normal quantile") + ylab("Simulated normals") +
  facet_wrap(~ sample, nrow = 1) 

```

Of the five simulated batches, only `Sample2` generates a *textbook*  q-q plot one would expect from a normally distributed batch of values. The other simulated batches generate plots that *could* lead one to question whether the data were pulled from a normal distribution, even though we know that they were!


## How normal q-q plots behave in the face of skewed data

It can be helpful to simulate distributions of difference skewness to see how a normal quantile plot may behave. In the following figure, the top row shows different density distribution plots; the bottom row shows the **normal q-q plots** for each distribution.


```{r, echo=FALSE, fig.width=9,fig.height=4}
# q.q function
# =============
# Function will generate q-q  plot and line
# given two vectors: a (y-axis) and b (x-axis)

q.q <- function(a,b, lin=TRUE){
  probs <-  c(0.25, 0.75)
  la <- length(a)
  lb <- length(b)
  a  <- sort(a)
  b  <- sort(b)
  fa <- ( 1:la - 0.5) / la
  fb <- ( 1:lb - 0.5) / lb
  if (la < lb) {
    b <- approx(fb, b, fa)$y 
  } else if( la > lb) {
    a <- approx(fa, a, fb)$y
  } else{}
  y <- quantile(a,probs)
  x <- quantile(b,probs)
  slope <- diff(y)/diff(x)
  int <- y[1] - slope * x[1]
  plot(a ~ b, cex=0.7, pch=20, col="blue")
  if (lin == TRUE) {
    abline(int,slope)
  }
}

# Set sample size and compute uniform
# values

n  <- 1000 # Number of simulated samples
fi <- (1:n - 0.5)/n
b.shp1 <- c(1, 5 , 50, 10, 10)
b.shp2 <- c(10,  10 , 70, 5, 1)

# Normal q-q plot
b  <- qnorm(fi)

OP <- par( mfcol = c(2,5), mar = c(2,2,1,1) )
for (i in 1:5 ) {
  a <- qbeta(fi,shape1=b.shp1[i], shape2 = b.shp2[i])
  plot(density(a),main=NA,xlab=NA)
  q.q(a,b)
}
par(OP)

```
